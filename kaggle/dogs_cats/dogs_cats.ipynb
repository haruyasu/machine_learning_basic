{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs vs Cats(CNNを用いた犬猫判定)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "from keras import callbacks\n",
    "from keras import optimizers\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import VGG16\n",
    "\n",
    "#元のデータセットを展開したディレクトリへのパス\n",
    "original_dataset_dir = \"./original/train\"\n",
    "\n",
    "#より小さなデータセットを格納するディレクトリへのパス\n",
    "base_dir = \"./cats_and_dogs_small\"\n",
    "os.mkdir(base_dir)\n",
    "\n",
    "#訓練、検証、テストデータセットを配置するディレクトリ\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir, \"validation\")\n",
    "os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(base_dir, \"test\")\n",
    "os.mkdir(test_dir)\n",
    "\n",
    "#訓練の猫の画像\n",
    "train_cats_dir = os.path.join(train_dir, \"cats\")\n",
    "os.mkdir(train_cats_dir)\n",
    "#訓練dogs\n",
    "train_dogs_dir = os.path.join(train_dir, \"dogs\")\n",
    "os.mkdir(train_dogs_dir)\n",
    "#検証cats\n",
    "validation_cats_dir = os.path.join(validation_dir, \"cats\")\n",
    "os.mkdir(validation_cats_dir)\n",
    "#検証dogs\n",
    "validation_dogs_dir = os.path.join(validation_dir, \"dogs\")\n",
    "os.mkdir(validation_dogs_dir)\n",
    "#テストcats\n",
    "test_cats_dir = os.path.join(test_dir, \"cats\")\n",
    "os.mkdir(test_cats_dir)\n",
    "#テストdogs\n",
    "test_dogs_dir = os.path.join(test_dir, \"dogs\")\n",
    "os.mkdir(test_dogs_dir)\n",
    "\n",
    "#最初の1000個の猫画像をtrain_cats_dirにコピー\n",
    "fnames = [\"cat.{}.jpg\".format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "#次の500個の猫をvalidation_cats_dirにコピー\n",
    "fnames = [\"cat.{}.jpg\".format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "#次の500個の猫をtest_cats_dirにコピー\n",
    "fnames = [\"cat.{}.jpg\".format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "#最初の1000個のいぬ画像をtrain_cats_dirにコピー\n",
    "fnames = [\"dog.{}.jpg\".format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "#次の500個のいぬをvalidation_cats_dirにコピー\n",
    "fnames = [\"dog.{}.jpg\".format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "#次の500個のいぬをtest_cats_dirにコピー\n",
    "fnames = [\"dog.{}.jpg\".format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_cats: 1000\n",
      "train_dogs: 1000\n",
      "validation_cats: 500\n",
      "validation_dogs: 500\n",
      "test_cats: 500\n",
      "test_dogs: 500\n"
     ]
    }
   ],
   "source": [
    "print(\"train_cats:\", len(os.listdir(train_cats_dir)))\n",
    "print(\"train_dogs:\", len(os.listdir(train_dogs_dir)))\n",
    "print(\"validation_cats:\", len(os.listdir(validation_cats_dir)))\n",
    "print(\"validation_dogs:\", len(os.listdir(validation_dogs_dir)))\n",
    "print(\"test_cats:\", len(os.listdir(test_cats_dir)))\n",
    "print(\"test_dogs:\", len(os.listdir(test_dogs_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "from keras import callbacks\n",
    "from keras import optimizers\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import VGG16\n",
    "\n",
    "#より小さなデータセットを格納するディレクトリへのパス\n",
    "base_dir = \"./cats_and_dogs_small\"\n",
    "\n",
    "#訓練、検証、テストデータセットを配置するディレクトリ\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "\n",
    "validation_dir = os.path.join(base_dir, \"validation\")\n",
    "\n",
    "test_dir = os.path.join(base_dir, \"test\")\n",
    "\n",
    "\n",
    "#訓練の猫の画像\n",
    "train_cats_dir = os.path.join(train_dir, \"cats\")\n",
    "\n",
    "#訓練dogs\n",
    "train_dogs_dir = os.path.join(train_dir, \"dogs\")\n",
    "\n",
    "#検証cats\n",
    "validation_cats_dir = os.path.join(validation_dir, \"cats\")\n",
    "\n",
    "#検証dogs\n",
    "validation_dogs_dir = os.path.join(validation_dir, \"dogs\")\n",
    "\n",
    "#テストcats\n",
    "test_cats_dir = os.path.join(test_dir, \"cats\")\n",
    "\n",
    "#テストdogs\n",
    "test_dogs_dir = os.path.join(test_dir, \"dogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_cats: 1000\n",
      "train_dogs: 1000\n",
      "validation_cats: 500\n",
      "validation_dogs: 500\n",
      "test_cats: 500\n",
      "test_dogs: 500\n"
     ]
    }
   ],
   "source": [
    "print(\"train_cats:\", len(os.listdir(train_cats_dir)))\n",
    "print(\"train_dogs:\", len(os.listdir(train_dogs_dir)))\n",
    "print(\"validation_cats:\", len(os.listdir(validation_cats_dir)))\n",
    "print(\"validation_dogs:\", len(os.listdir(validation_dogs_dir)))\n",
    "print(\"test_cats:\", len(os.listdir(test_cats_dir)))\n",
    "print(\"test_dogs:\", len(os.listdir(test_dogs_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習済みCNNを使用(特徴抽出)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0918 14:47:22.500289 18480 deprecation_wrapper.py:119] From c:\\users\\haruk\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0918 14:47:22.537222 18480 deprecation_wrapper.py:119] From c:\\users\\haruk\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0918 14:47:22.544189 18480 deprecation_wrapper.py:119] From c:\\users\\haruk\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0918 14:47:22.581100 18480 deprecation_wrapper.py:119] From c:\\users\\haruk\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0918 14:47:22.876975 18480 deprecation_wrapper.py:119] From c:\\users\\haruk\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0918 14:47:22.877972 18480 deprecation_wrapper.py:119] From c:\\users\\haruk\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base = VGG16(weights=\"imagenet\", include_top=False, input_shape=(150, 150, 3))\n",
    "\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ拡張を行う特徴抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 16,812,353\n",
      "Trainable params: 16,812,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation=\"relu\"))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルの訓練の前に"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights before freezing the conv base: 30\n",
      "This is the number of trainable weights after freezing the conv base: 4\n"
     ]
    }
   ],
   "source": [
    "print('This is the number of trainable weights '\n",
    "      'before freezing the conv base:', len(model.trainable_weights))\n",
    "\n",
    "conv_base.trainable = False\n",
    "\n",
    "print('This is the number of trainable weights '\n",
    "      'after freezing the conv base:', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 拡張してモデル全体を訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0918 14:49:07.339319 18480 deprecation_wrapper.py:119] From c:\\users\\haruk\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0918 14:49:07.346301 18480 deprecation.py:323] From c:\\users\\haruk\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Epoch 1/30\n",
      " - 20s - loss: 0.5989 - acc: 0.6855 - val_loss: 0.4658 - val_acc: 0.8150\n",
      "Epoch 2/30\n",
      " - 17s - loss: 0.4881 - acc: 0.7755 - val_loss: 0.3736 - val_acc: 0.8600\n",
      "Epoch 3/30\n",
      " - 17s - loss: 0.4388 - acc: 0.8010 - val_loss: 0.3292 - val_acc: 0.8820\n",
      "Epoch 4/30\n",
      " - 17s - loss: 0.4021 - acc: 0.8205 - val_loss: 0.3313 - val_acc: 0.8620\n",
      "Epoch 5/30\n",
      " - 17s - loss: 0.3821 - acc: 0.8310 - val_loss: 0.2976 - val_acc: 0.8920\n",
      "Epoch 6/30\n",
      " - 17s - loss: 0.3649 - acc: 0.8330 - val_loss: 0.2795 - val_acc: 0.8910\n",
      "Epoch 7/30\n",
      " - 17s - loss: 0.3542 - acc: 0.8510 - val_loss: 0.2777 - val_acc: 0.8980\n",
      "Epoch 8/30\n",
      " - 17s - loss: 0.3565 - acc: 0.8460 - val_loss: 0.2717 - val_acc: 0.8890\n",
      "Epoch 9/30\n",
      " - 17s - loss: 0.3434 - acc: 0.8470 - val_loss: 0.2651 - val_acc: 0.8990\n",
      "Epoch 10/30\n",
      " - 17s - loss: 0.3383 - acc: 0.8560 - val_loss: 0.2654 - val_acc: 0.9010\n",
      "Epoch 11/30\n",
      " - 17s - loss: 0.3215 - acc: 0.8575 - val_loss: 0.2575 - val_acc: 0.9000\n",
      "Epoch 12/30\n",
      " - 17s - loss: 0.3263 - acc: 0.8575 - val_loss: 0.2560 - val_acc: 0.9050\n",
      "Epoch 13/30\n",
      " - 17s - loss: 0.3105 - acc: 0.8665 - val_loss: 0.2502 - val_acc: 0.9010\n",
      "Epoch 14/30\n",
      " - 17s - loss: 0.3206 - acc: 0.8680 - val_loss: 0.2456 - val_acc: 0.9010\n",
      "Epoch 15/30\n",
      " - 17s - loss: 0.3087 - acc: 0.8710 - val_loss: 0.2429 - val_acc: 0.9060\n",
      "Epoch 16/30\n",
      " - 17s - loss: 0.3105 - acc: 0.8625 - val_loss: 0.2526 - val_acc: 0.8970\n",
      "Epoch 17/30\n",
      " - 17s - loss: 0.2993 - acc: 0.8680 - val_loss: 0.2515 - val_acc: 0.8950\n",
      "Epoch 18/30\n",
      " - 17s - loss: 0.3062 - acc: 0.8625 - val_loss: 0.2563 - val_acc: 0.8900\n",
      "Epoch 19/30\n",
      " - 17s - loss: 0.3128 - acc: 0.8630 - val_loss: 0.2454 - val_acc: 0.8960\n",
      "Epoch 20/30\n",
      " - 17s - loss: 0.2969 - acc: 0.8685 - val_loss: 0.2441 - val_acc: 0.9010\n",
      "Epoch 21/30\n",
      " - 17s - loss: 0.2907 - acc: 0.8780 - val_loss: 0.2405 - val_acc: 0.9020\n",
      "Epoch 22/30\n",
      " - 17s - loss: 0.2870 - acc: 0.8725 - val_loss: 0.2407 - val_acc: 0.9070\n",
      "Epoch 23/30\n",
      " - 17s - loss: 0.3093 - acc: 0.8590 - val_loss: 0.2407 - val_acc: 0.9020\n",
      "Epoch 24/30\n",
      " - 17s - loss: 0.2891 - acc: 0.8775 - val_loss: 0.2594 - val_acc: 0.8860\n",
      "Epoch 25/30\n",
      " - 17s - loss: 0.2941 - acc: 0.8685 - val_loss: 0.2379 - val_acc: 0.9030\n",
      "Epoch 26/30\n",
      " - 17s - loss: 0.2987 - acc: 0.8670 - val_loss: 0.2377 - val_acc: 0.9030\n",
      "Epoch 27/30\n",
      " - 17s - loss: 0.2823 - acc: 0.8835 - val_loss: 0.2353 - val_acc: 0.9060\n",
      "Epoch 28/30\n",
      " - 17s - loss: 0.2787 - acc: 0.8855 - val_loss: 0.2455 - val_acc: 0.9010\n",
      "Epoch 29/30\n",
      " - 17s - loss: 0.2678 - acc: 0.8915 - val_loss: 0.2368 - val_acc: 0.9060\n",
      "Epoch 30/30\n",
      " - 17s - loss: 0.2698 - acc: 0.8830 - val_loss: 0.2388 - val_acc: 0.9040\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "# 検証データは水増しすべきでないことに注意\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(150, 150), batch_size=20, class_mode='binary') \n",
    "validation_generator = test_datagen.flow_from_directory(validation_dir,target_size=(150, 150),batch_size=20,class_mode='binary')\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizers.RMSprop(lr=2e-5), metrics=[\"acc\"])\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=30,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,\n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cats_and_dogs_small.h5')\n",
    "with open(\"history.pickle\", mode=\"wb\") as f:\n",
    "    pickle.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n",
      "test acc: 0.902999997138977\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(test_dir, target_size=(150, 150), batch_size=20, class_mode=\"binary\")\n",
    "\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\n",
    "\n",
    "print(\"test acc:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提出用ファイルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = [0]*12500\n",
    "x_test = [0]*12500\n",
    "for i in range(12499):\n",
    "    # filenameのUserNameの部分は変更してください。\n",
    "    filename = \"./original/test/\" + str(i+1) + \".jpg\"\n",
    "    img[i] = image.load_img(filename, target_size=(150, 150))\n",
    "    x_test[i] = image.img_to_array(img[i])\n",
    "    x_test[i] = np.expand_dims(x_test[i], axis=0)\n",
    "    x_test[i] = x_test[i]/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\haruk\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\engine\\saving.py:327: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    }
   ],
   "source": [
    "model = models.load_model(\"cats_and_dogs_small.h5\")\n",
    "with open(\"history.pickle\", mode=\"rb\") as f:\n",
    "    history = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "expect = [0]*12500\n",
    "for i in range(12499):\n",
    "     expect[i]= model.predict(x_test[i], batch_size = 20 ).flatten().tolist()[0]\n",
    "\n",
    "id =[]\n",
    "for i in range(1, 12501):\n",
    "    id.append(i)\n",
    "\n",
    "submission_DC = pd.DataFrame({\"Id\" : id, \"label\" : expect})\n",
    "submission_DC.to_csv(\"submission_DC.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
