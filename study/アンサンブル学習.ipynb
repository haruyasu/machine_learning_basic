{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# アンサンブル学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "アンサンブル学習とは複数のモデルを組み合わせて予測する手法です。  \n",
    "ポイントは性能の低い学習器(弱学習器)を組み合わせて、高性能な学習器を作ることができる点です。  \n",
    "アンサンブル学習には、バギングやブースティングなどがあります"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# バギング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "バギング(bootstrap aggregating: bagging)は、元の学習データからランダムにn行のデータを重複を許し抽出し、新しい学習データを作成するということを繰り返します。  \n",
    "これをブートストラップと言います。  \n",
    "学習器を並列に学習して組み合わせる手法だと言えます。  \n",
    "分類の場合、結果の集約、回帰の場合は平均値をとったりします。  \n",
    "バギングの利点として、学習器を並列で学習できることや、過学習しにくいことが挙げられます。  \n",
    "以前みたランダムフォレストはバギングの1種です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9370629370629371\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(cancer.data, \n",
    "                                                   cancer.target, stratify=cancer.target,\n",
    "                                                   random_state=66)\n",
    "\n",
    "model = BaggingClassifier(KNeighborsClassifier(), n_estimators=100, \n",
    "                                random_state=0)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "score  = model.score(x_test, y_test)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ブースティング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ブースティング(boosting)とは、学習データもモデルに逐次的に生成、構築しています。  \n",
    "ブースティングは学習不足(underfitting)傾向の時に効果的な手法と言われています。  \n",
    "ポイントは、学習器を順番に学習し、組み合わせていると言えます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9044603110849393"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "x = boston.data\n",
    "y = boston.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1)\n",
    "\n",
    "model = AdaBoostRegressor(DecisionTreeRegressor())\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost（eXtreme Gradient Boosting / 勾配ブースティング回帰木）とは、アンサンブル学習の一つで、ブースティングと決定木を組み合わせています。  \n",
    "ブースティングとは、弱いモデル（弱学習器と呼びます）を複数作成し、一つ前の学習器の誤りを次の学習器が修正するという操作を繰り返し行うことで性能を向上させる手法です。  \n",
    "勾配ブースティング回帰木では、浅い決定木を複数作成し、それぞれの決定木はデータの一部に対してしか良い予測を行うことができないため、ブースティングを行うことで性能を向上させています。  \n",
    "パラメータ設定に敏感という欠点がありますが、正しく設定すればランダムフォレストよりも良い性能となります。  \n",
    "また、XGBoostの名前に「回帰」とありますが、回帰と分類のどちらでも使用可能です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回帰モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:54:38] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "0.8977199651347564\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# bostonのデータセットをインポート\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "\n",
    "x = boston.data\n",
    "y = boston.target\n",
    "df = pd.DataFrame(x, columns =  boston.feature_names)\n",
    "df['target'] = boston.target\n",
    "\n",
    "# train_test_splitでトレーニングデータとテストデータを分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1)\n",
    "\n",
    "# xgboostをインポートして、回帰モデルであるXGBRegressorをインスタンス化\n",
    "import xgboost as xgb\n",
    "xgbr = xgb.XGBRegressor()\n",
    "xgbr.fit(x_train, y_train)\n",
    "\n",
    "# テストデータの予測\n",
    "pred = xgbr.predict(x_test)\n",
    "\n",
    "# モデルの評価とスコアの確認\n",
    "from sklearn.metrics import r2_score\n",
    "print(r2_score(pred, y_test)) # 0.8977199651347564"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分類モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# irisのデータセットをインポート\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "df = pd.DataFrame(x)\n",
    "df['target'] = y\n",
    "\n",
    "# train_test_splitでトレーニングデータとテストデータを分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1)\n",
    "\n",
    "# xgboostをインポートして、分類モデルであるXGBClassifierをインスタンス化\n",
    "import xgboost as xgb\n",
    "xgbc = xgb.XGBClassifier()\n",
    "xgbc.fit(x_train, y_train)\n",
    "\n",
    "# テストデータの予測\n",
    "pred = xgbc.predict(x_test)\n",
    "\n",
    "#モデルの評価とスコアの確認\n",
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(pred, y_test)\n",
    "print(score) # 0.9736842105263158"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
