{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNによる画像認識"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 8s 0us/step\n",
      "(50000, 32, 32, 3) (50000, 1)\n",
      "(10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import tensorflow as tf\n",
    "import pickle as p # python2系はcPickle\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "in_shape = (32, 32, 3)\n",
    "cls_num = 3\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(16, 3, 3, border_mode=\"same\", input_shape=in_shape))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Convolution2D(16, 3, 3, border_mode=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Dropout(0.5))\n",
    "    # model.add(Dropout(1))\n",
    "\n",
    "    model.add(Convolution2D(32, 3, 3, border_mode=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Convolution2D(32, 3, 3, border_mode=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Dropout(0.5))\n",
    "    # model.add(Dropout(1))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Dropout(0.5))\n",
    "    # model.add(Dropout(1))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Dropout(0.5))\n",
    "    # model.add(Dropout(1))\n",
    "\n",
    "    model.add(Convolution2D(128, 3, 3, border_mode=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    # model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    # model.add(Dropout(1))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(cls_num))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\",\n",
    "        metrics   = [\"accuracy\"],\n",
    "        optimizer = \"adam\"\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def change3class(exp_val, obj_val):\n",
    "    new_exp = []\n",
    "    new_obj = []\n",
    "    for (x, y) in zip(exp_val, obj_val):\n",
    "        if y == 3:\n",
    "            new_exp.append(x)\n",
    "            new_obj.append(0)\n",
    "        elif y == 5:\n",
    "            new_exp.append(x)\n",
    "            new_obj.append(1)\n",
    "        elif y == 1:\n",
    "            new_exp.append(x)\n",
    "            new_obj.append(2)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    new_exp = np.array(new_exp)\n",
    "    return new_exp, new_obj\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "    print(X_train.shape, y_train.shape)\n",
    "    print(X_test.shape, y_test.shape)\n",
    "\n",
    "    X_train, y_train = change3class(X_train, y_train)\n",
    "    X_test, y_test = change3class(X_test, y_test)\n",
    "\n",
    "    y_train = np_utils.to_categorical(y_train)\n",
    "    y_test  = np_utils.to_categorical(y_test)\n",
    "\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test  = X_test.astype('float32')\n",
    "    X_train /= 255.0\n",
    "    X_test /= 255.0\n",
    "\n",
    "    print(\"X_train\", X_train.shape)\n",
    "    print(\"y_train\", y_train.shape)\n",
    "    print(\"X_test\", X_test.shape)\n",
    "    print(\"y_test\", y_test.shape)\n",
    "\n",
    "    model = build_model()\n",
    "    model.fit(X_train, y_train,\n",
    "        nb_epoch=250,\n",
    "        batch_size=128,\n",
    "        validation_data=(X_test, y_test)\n",
    "    )\n",
    "\n",
    "    json_string = model.to_json()\n",
    "    open('test.json', 'w').write(json_string)\n",
    "    model.save_weights('test.hdf5')\n",
    "\n",
    "    # evaluate\n",
    "    score = model.evaluate(X_test, y_test)\n",
    "    print(\"test loss\", score[0])\n",
    "    print(\"test acc\",  score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import sys, os\n",
    "import scipy\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from keras.models import model_from_json\n",
    "\n",
    "import json\n",
    "\n",
    "imsize = (32, 32)\n",
    "# 下記フォルダには、適当な犬と猫と自動車の画像を入れて下さい。\n",
    "testpic = \"./testpic/\"\n",
    "keras_model = \"./test.json\"\n",
    "keras_param = \"./test.hdf5\"\n",
    "\n",
    "\n",
    "def load_image(path):\n",
    "img = scipy.misc.imread(path, mode=\"RGB\")\n",
    "img = scipy.misc.imresize(img, imsize)\n",
    "img = img / 255.0\n",
    "return img\n",
    "\n",
    "def get_file(dir_path):\n",
    "\"\"\"\n",
    "testpicディレクトリの配下の画像を1つのリストにして返す\n",
    "['244573113_thumb.jpg', 'car1.jpg', 'car2.jpg', 'car3.jpg', 'cat1.jpg', 'cat2.jpg', 'cat3.jpg', 'dog1.jpg', 'dog2.jpg', 'dog3.jpg', 'dog4.jpg', 'dog5.jpg', 'dog6.jpg', 'dog7.jpg']\n",
    "\"\"\"\n",
    "filenames = os.listdir(dir_path)\n",
    "return filenames\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    pic = get_file(testpic)\n",
    "\n",
    "    model = model_from_json(open(keras_model).read())\n",
    "    model.load_weights(keras_param)\n",
    "    model.summary()\n",
    "\n",
    "    for i in pic:\n",
    "    print(i) # ファイル名の出力\n",
    "    img = load_image(testpic + i)\n",
    "    #vec = model.predict(np.array([img]), batch_size=1)\n",
    "    prd = model.predict(np.array([img]))\n",
    "    print(prd)\n",
    "    prelabel = np.argmax(prd, axis=1)\n",
    "\n",
    "    # 各画像ファイルに猫ならファイル名+0が、犬ならファイル名+1、乗り物ならファイル名+2のラベルが付いている\n",
    "    if prelabel == 0:\n",
    "        print(\">>> 猫\")\n",
    "    elif prelabel == 1:\n",
    "        print(\">>> 犬\")\n",
    "    elif prelabel == 2:\n",
    "        print(\">>> 乗り物\")\n",
    "\n",
    "    print(\"#\"*55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.misc\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "cat_dir = \"./cat/\"\n",
    "dog_dir = \"./dog/\"\n",
    "car_dir = \"./car/\"\n",
    "\n",
    "cat_train_image_dir = \"./cat_train/\"\n",
    "cat_test_image_dir  = \"./cat_test/\"\n",
    "\n",
    "dog_train_image_dir = \"./dog_train/\"\n",
    "dog_test_image_dir  = \"./dog_test/\"\n",
    "\n",
    "car_train_image_dir = \"./car_train/\"\n",
    "car_test_image_dir  = \"./car_test/\"\n",
    "\n",
    "in_shape = (120, 120, 3)\n",
    "\n",
    "\n",
    "def init():\n",
    "    for i in [cat_train_image_dir, cat_test_image_dir, dog_train_image_dir, dog_test_image_dir, car_train_image_dir, car_test_image_dir]:\n",
    "        if not os.path.isdir(i):\n",
    "            os.makedirs(i)\n",
    "\n",
    "def load_image(path):\n",
    "    img = scipy.misc.imread(path, mode=\"RGB\")\n",
    "    if img.shape != in_shape:\n",
    "        return\n",
    "    return img\n",
    "\n",
    "def get_dirfile(dir_path):\n",
    "    filenames = os.listdir(dir_path)\n",
    "    return filenames\n",
    "\n",
    "def load_id_dict(id_dict_path):\n",
    "    with open(id_dict_path, \"rb\") as f:\n",
    "        id_dict = pickle.load(f)\n",
    "    print(id_dict_path + \"をロードしました．\")\n",
    "    return id_dict\n",
    "\n",
    "def usable(img_files, images_dir):\n",
    "    usable = []\n",
    "    for i in img_files:\n",
    "        img = load_image(images_dir + i)\n",
    "        if img is None:\n",
    "            continue\n",
    "        else:\n",
    "            usable.append(i)\n",
    "    return usable\n",
    "\n",
    "def dataset(usable):\n",
    "    trainf = random.sample(usable, 800)\n",
    "    testf = set(usable) - set(trainf)\n",
    "    testf = list(testf)\n",
    "    return trainf, testf\n",
    "\n",
    "\n",
    "if __name__ ==\"__main__\":\n",
    "    init()\n",
    "\n",
    "    cat_files = get_dirfile(cat_dir)\n",
    "    dog_files = get_dirfile(dog_dir)\n",
    "    car_files = get_dirfile(car_dir)\n",
    "\n",
    "    cat_usable = usable(cat_files,cat_dir)\n",
    "    dog_usable = usable(dog_files, dog_dir)\n",
    "    car_usable = usable(car_files, car_dir)\n",
    "\n",
    "    print(\"cat_usable\", len(cat_usable))\n",
    "    print(\"dog_usable\", len(dog_usable))\n",
    "    print(\"car_usable\", len(car_usable))\n",
    "\n",
    "    cat_train, cat_test = dataset(cat_usable)\n",
    "    dog_train, dog_test = dataset(dog_usable)\n",
    "    car_train, car_test = dataset(car_usable)\n",
    "    print(\"cat_train\", len(cat_train))\n",
    "    print(\"cat_test\", len(cat_test))\n",
    "    print(\"dog_train\", len(dog_train))\n",
    "    print(\"dog_test\", len(dog_test))\n",
    "    print(\"car_train\", len(car_train))\n",
    "    print(\"car_test\", len(car_test))\n",
    "\n",
    "\n",
    "    for i in cat_train:\n",
    "        shutil.copy2(cat_dir + i, cat_train_image_dir + i)\n",
    "    for i in cat_test:\n",
    "        shutil.copy2(cat_dir + i, cat_test_image_dir + i)\n",
    "\n",
    "    for i in dog_train:\n",
    "        shutil.copy2(dog_dir + i, dog_train_image_dir + i)\n",
    "    for i in dog_test:\n",
    "        shutil.copy2(dog_dir + i, dog_test_image_dir + i)\n",
    "\n",
    "    for i in car_train:\n",
    "        shutil.copy2(car_dir + i, car_train_image_dir + i)\n",
    "    for i in car_test:\n",
    "        shutil.copy2(car_dir + i, car_test_image_dir + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gpu_config\n",
    "# gpu_config.set_tensorflow([3])\n",
    "# import tensorflow.python.ops.tensor_array_ops\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.misc\n",
    "import random\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "\n",
    "\n",
    "cat_train_image_dir = \"./cat_train/\"\n",
    "cat_test_image_dir  = \"./cat_test/\"\n",
    "dog_train_image_dir = \"./dog_train/\"\n",
    "dog_test_image_dir  = \"./dog_test/\"\n",
    "car_train_image_dir = \"./car_train/\"\n",
    "car_test_image_dir  = \"./car_test/\"\n",
    "in_shape = (120, 120, 3)\n",
    "cls_num  = 3\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode=\"same\", input_shape=in_shape))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D())\n",
    "\n",
    "    model.add(Convolution2D(32, 3, 3, border_mode=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(MaxPooling2D())\n",
    "\n",
    "    model.add(Convolution2D(16, 3, 3, border_mode=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D())\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dense(cls_num))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def load_image(path):\n",
    "    img = scipy.misc.imread(path, mode=\"RGB\")\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "def get_file(dir_path):\n",
    "    filenames = os.listdir(dir_path)\n",
    "    return filenames\n",
    "\n",
    "def mk_x(files, images_dir):\n",
    "    X_train =[]\n",
    "    for i in files:\n",
    "        img = load_image(images_dir + i)\n",
    "        X_train.append(img)\n",
    "    return X_train\n",
    "\n",
    "def mk_y(num):\n",
    "    wrap_label = []\n",
    "    dog_label = [1,0,0] # 800\n",
    "    cat_label = [0,1,0] # 800\n",
    "    car_label = [0,0,1] # 800\n",
    "    for i in range(num):\n",
    "        wrap_label.append(dog_label)\n",
    "    for i in range(num):\n",
    "        wrap_label.append(cat_label)\n",
    "    for i in range(num):\n",
    "        wrap_label.append(car_label)\n",
    "\n",
    "    print(np.shape(wrap_label))\n",
    "    return wrap_label\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cat_train = get_file(cat_train_image_dir)\n",
    "    cat_test  = get_file(cat_test_image_dir)\n",
    "    dog_train = get_file(dog_train_image_dir)\n",
    "    dog_test  = get_file(dog_test_image_dir)\n",
    "    car_train = get_file(car_train_image_dir)\n",
    "    car_test  = get_file(car_test_image_dir)\n",
    "\n",
    "    cat_train = mk_x(cat_train, cat_train_image_dir)\n",
    "    cat_test  = mk_x(cat_test, cat_test_image_dir)\n",
    "    dog_train = mk_x(dog_train, dog_train_image_dir)\n",
    "    dog_test  = mk_x(dog_test, dog_test_image_dir)\n",
    "    car_train = mk_x(car_train, car_train_image_dir)\n",
    "    car_test  = mk_x(car_test, car_test_image_dir)\n",
    "\n",
    "    cat_train = np.array(cat_train)\n",
    "    cat_test  = np.array(cat_test)\n",
    "    dog_train = np.array(dog_train)\n",
    "    dog_test  = np.array(dog_test)\n",
    "    car_train = np.array(car_train)\n",
    "    car_test  = np.array(car_test)\n",
    "\n",
    "    X_train = np.concatenate((cat_train, dog_train, car_train))\n",
    "    X_test  = np.concatenate((cat_test, dog_test, car_test))\n",
    "    y_train = np.array(mk_y(800))\n",
    "    y_test  = np.array(mk_y(200))\n",
    "\n",
    "\n",
    "    print(\"X_train\", X_train.shape)\n",
    "    print(\"y_train\", y_train.shape)\n",
    "    print(\"X_test\", X_test.shape)\n",
    "    print(\"y_test\", y_test.shape)\n",
    "\n",
    "    model = build_model()\n",
    "    model.fit(X_train, y_train, nb_epoch=150, batch_size=128, validation_data=(X_test, y_test))\n",
    "\n",
    "    json_string = model.to_json()\n",
    "    open('model2.json', 'w').write(json_string)\n",
    "    model.save_weights('model2.hdf5')\n",
    "\n",
    "    # evaluate\n",
    "    score = model.evaluate(X_test, y_test)\n",
    "    print(\"test loss\", score[0])\n",
    "    print(\"test acc\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
