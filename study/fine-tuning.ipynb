{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "\n",
    "'''\n",
    "設定\n",
    "'''\n",
    "\n",
    "## 学習のハイパーパラメータ\n",
    "batch_size = 128\n",
    "n_class = 5\n",
    "epochs = 5\n",
    "\n",
    "## 画像の入力サイズ\n",
    "img_rows, img_cols = 28, 28\n",
    "## CNNのハイパーパラメータ\n",
    "filters = 32\n",
    "pool_size = 2\n",
    "kernel_size = 3\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ソース、ターゲットデータ作成\n",
    "'''\n",
    "## MNISTのデータセットを取得する．\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "## データセットを [0..4] と [5..9] に分割する．\n",
    "x_train_lt5 = x_train[y_train < 5]\n",
    "y_train_lt5 = y_train[y_train < 5]\n",
    "x_test_lt5 = x_test[y_test < 5]\n",
    "y_test_lt5 = y_test[y_test < 5]\n",
    "\n",
    "x_train_gte5 = x_train[y_train >= 5]\n",
    "y_train_gte5 = y_train[y_train >= 5] - 5\n",
    "x_test_gte5 = x_test[y_test >= 5]\n",
    "y_test_gte5 = y_test[y_test >= 5] - 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ネットワークの構造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ネットワーク構造の定義\n",
    "'''\n",
    "## 特徴抽出層 (feature_layers) の定義\n",
    "feature_layers = [\n",
    "    Conv2D(filters, kernel_size,\n",
    "           padding='valid',\n",
    "           input_shape=input_shape),\n",
    "    Activation('relu'),\n",
    "    Conv2D(filters, kernel_size),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=pool_size),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "]\n",
    "\n",
    "## 識別層 (classification_layers) の定義\n",
    "classification_layers = [\n",
    "    Dense(128),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(n_class),\n",
    "    Activation('softmax')\n",
    "]\n",
    "\n",
    "## 畳み込み層 + 全連結層 のモデルを作る．\n",
    "model = Sequential(feature_layers + classification_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルの学習関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train, test, n_class):\n",
    "    '''\n",
    "    前処理\n",
    "    '''\n",
    "    x_train = train[0].reshape((train[0].shape[0],) + input_shape)\n",
    "    x_test = test[0].reshape((test[0].shape[0],) + input_shape)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "    # one-hot ベクトルに変換\n",
    "    y_train = keras.utils.to_categorical(train[1], n_class)\n",
    "    y_test = keras.utils.to_categorical(test[1], n_class)\n",
    "\n",
    "    '''\n",
    "    モデルの設定\n",
    "    '''\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    '''\n",
    "    トレーニングデータによるモデルの学習\n",
    "    '''\n",
    "    t = datetime.datetime.now()\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test))\n",
    "    print('Training time:{}'.format(datetime.datetime.now() - t))\n",
    "\n",
    "    '''\n",
    "    テストデータによるモデルの評価\n",
    "    '''\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ステップ1. ソースモデルの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0906 15:45:54.606003 20124 deprecation_wrapper.py:119] From C:\\Users\\haruk\\Anaconda3\\envs\\ai-gpu\\Lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0906 15:45:54.621960 20124 deprecation_wrapper.py:119] From C:\\Users\\haruk\\Anaconda3\\envs\\ai-gpu\\Lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0906 15:45:54.687783 20124 deprecation.py:323] From C:\\Users\\haruk\\Anaconda3\\envs\\ai-gpu\\Lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (30596, 28, 28, 1)\n",
      "30596 train samples\n",
      "5139 test samples\n",
      "Train on 30596 samples, validate on 5139 samples\n",
      "Epoch 1/5\n",
      "30596/30596 [==============================] - 7s 220us/step - loss: 0.1358 - acc: 0.9586 - val_loss: 0.0190 - val_acc: 0.9934\n",
      "Epoch 2/5\n",
      "30596/30596 [==============================] - 3s 97us/step - loss: 0.0365 - acc: 0.9887 - val_loss: 0.0119 - val_acc: 0.9953\n",
      "Epoch 3/5\n",
      "30596/30596 [==============================] - 3s 98us/step - loss: 0.0234 - acc: 0.9930 - val_loss: 0.0081 - val_acc: 0.9975\n",
      "Epoch 4/5\n",
      "30596/30596 [==============================] - 3s 97us/step - loss: 0.0196 - acc: 0.9939 - val_loss: 0.0069 - val_acc: 0.9973\n",
      "Epoch 5/5\n",
      "30596/30596 [==============================] - 3s 97us/step - loss: 0.0150 - acc: 0.9951 - val_loss: 0.0046 - val_acc: 0.9984\n",
      "Training time:0:00:18.894578\n",
      "Test score: 0.004625545279065406\n",
      "Test accuracy: 0.9984432769021211\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "fine-tuning の元となるモデルの学習\n",
    "'''\n",
    "## [0..4] の5種類の画像を用いてモデルを学習する．\n",
    "train_model(model,\n",
    "            (x_train_lt5, y_train_lt5),\n",
    "            (x_test_lt5, y_test_lt5), n_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ステップ2. 重み固定の範囲を決定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "fine-tuning\n",
    "'''\n",
    "## 畳み込み層を固定する．\n",
    "for l in feature_layers:\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ステップ3. ターゲットモデルの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (29404, 28, 28, 1)\n",
      "29404 train samples\n",
      "4861 test samples\n",
      "Train on 29404 samples, validate on 4861 samples\n",
      "Epoch 1/5\n",
      "29404/29404 [==============================] - 2s 65us/step - loss: 0.3635 - acc: 0.9068 - val_loss: 0.0562 - val_acc: 0.9817\n",
      "Epoch 2/5\n",
      "29404/29404 [==============================] - 2s 56us/step - loss: 0.0833 - acc: 0.9753 - val_loss: 0.0346 - val_acc: 0.9885\n",
      "Epoch 3/5\n",
      "29404/29404 [==============================] - 2s 55us/step - loss: 0.0624 - acc: 0.9810 - val_loss: 0.0291 - val_acc: 0.9914\n",
      "Epoch 4/5\n",
      "29404/29404 [==============================] - 2s 55us/step - loss: 0.0471 - acc: 0.9859 - val_loss: 0.0284 - val_acc: 0.9909\n",
      "Epoch 5/5\n",
      "29404/29404 [==============================] - 2s 54us/step - loss: 0.0425 - acc: 0.9862 - val_loss: 0.0235 - val_acc: 0.9922\n",
      "Training time:0:00:08.553231\n",
      "Test score: 0.023548187684005566\n",
      "Test accuracy: 0.992182678461222\n"
     ]
    }
   ],
   "source": [
    "## [5..9] の数字データを用いてモデルを学習する．\n",
    "train_model(model,\n",
    "            (x_train_gte5, y_train_gte5),\n",
    "            (x_test_gte5, y_test_gte5), n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ネットワークの構造を画像で出力する．\n",
    "plot_model(model,\n",
    "           to_file='./result/model.png',\n",
    "           show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
